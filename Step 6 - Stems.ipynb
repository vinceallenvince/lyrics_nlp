{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Stemming\n",
    "Reduce the cleaned tokens to their stems. We'll later get the frequency distribution of the stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from nltk.corpus.reader import CategorizedPlaintextCorpusReader\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "outputFile = \"lyrics_stems.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stem(tokens):\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        tk = token.decode('utf8')\n",
    "        if re.search('[a-zA-Z]', tk):\n",
    "            filtered_tokens.append(tk)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = CategorizedPlaintextCorpusReader(\"./corpus/lyrics/tfidf/\", r\".*\\.txt\", cat_pattern=r\"(\\w+)/*\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "04CpzA2BdOLEz7EMp5uwTU.txt    baby days sun nights rain summer simple plain ...\n",
       "07GilNHSfS5oicUgHgU7VG.txt    man live hype real ting pull lexus' like hit l...\n",
       "08zJpaUQVi9FrKv2e32Bah.txt    one goes sides world wide let playa ass nigga ...\n",
       "0AAyo5bMIVgVxv9DF6XV2B.txt    little chilly stand beyond let friends friends...\n",
       "0GSrlvOgiCSpBLeAukOIjT.txt    panda fam trust niggas jam hustle man want cru...\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics = []\n",
    "for filen in corpus.fileids():\n",
    "    with open(\"./corpus/lyrics/tokenized/\" + filen, 'rb') as handle:\n",
    "        lyrics.append(handle.read())\n",
    "\n",
    "# create a Series to index lyrics by filename\n",
    "lyrics_by_file = Series(lyrics,index=corpus.fileids())\n",
    "lyrics_by_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem\n",
    "We'll stem using the Snowball stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "04CpzA2BdOLEz7EMp5uwTU.txt    babi day sun night rain summer simpl plain fou...\n",
       "07GilNHSfS5oicUgHgU7VG.txt    man live hype real ting pull lexus like hit li...\n",
       "08zJpaUQVi9FrKv2e32Bah.txt    one goe side world wide let playa ass nigga th...\n",
       "0AAyo5bMIVgVxv9DF6XV2B.txt    littl chilli stand beyond let friend friend an...\n",
       "0GSrlvOgiCSpBLeAukOIjT.txt    panda fam trust nigga jam hustl man want crush...\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_stemmed = []\n",
    "for filen, lyrics in lyrics_by_file.iteritems():\n",
    "    lyrics_stemmed.append(' '.join(stem(lyrics.split(' '))))\n",
    "\n",
    "# create a Series to index cleaned lyrics by filename\n",
    "lyrics_stemmed_by_file = Series(lyrics_stemmed,index=corpus.fileids())\n",
    "lyrics_stemmed_by_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeFile(path, text):\n",
    "    text_file = open(path, \"w\") \n",
    "    text_file.write(text + \" \")\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filen, lyrics in lyrics_stemmed_by_file.iteritems():\n",
    "    writeFile(\"./corpus/lyrics/stemmed/\" + filen, lyrics.encode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
